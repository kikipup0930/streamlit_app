# utils.py

import io
import pandas as pd
from io import StringIO
from datetime import datetime
from PIL import Image, ImageOps, ImageFilter
import requests
import streamlit as st
from openai import OpenAI
from azure.storage.blob import BlobServiceClient

# ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰è¨­å®šå€¤ã‚’å–å¾—
AZURE_ENDPOINT = st.secrets["AZURE_ENDPOINT"]
AZURE_KEY = st.secrets["AZURE_KEY"]
AZURE_STORAGE_CONNECTION_STRING = st.secrets["AZURE_CONNECTION_STRING"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=OPENAI_API_KEY)

# ç”»åƒå‰å‡¦ç†ï¼ˆç™½é»’åŒ–ãƒ»ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ï¼‰
def preprocess_image(image: Image.Image) -> Image.Image:
    image = image.convert("L")
    image = image.filter(ImageFilter.MedianFilter(size=3))
    image = ImageOps.autocontrast(image)
    return image

# OCRå®Ÿè¡Œï¼ˆAzure Read APIã«å¯¾å¿œï¼‰
def run_ocr(image: Image.Image) -> str:
    image = preprocess_image(image)
    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    img_bytes = buffer.getvalue()

    try:
        response = requests.post(
            url=f"{AZURE_ENDPOINT}/computervision/imageanalysis:analyze?api-version=2023-10-01&features=read",
            headers={
                "Ocp-Apim-Subscription-Key": AZURE_KEY,
                "Content-Type": "application/octet-stream"
            },
            params={"language": "ja", "model-version": "latest"},
            data=img_bytes
        )

        result = response.json()

        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆStreamlitä¸Šã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¯è¦–åŒ–ï¼‰
        st.subheader("ğŸ” Azureãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
        st.json(result)

        read_result = result.get("readResult", {})

        # contentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆç°¡æ˜“ãƒ†ã‚­ã‚¹ãƒˆï¼‰ãŒã‚ã‚Œã°ãã‚Œã‚’è¿”ã™
        if "content" in read_result:
            return read_result["content"].strip()

        # pagesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¯¾å¿œï¼ˆå¾“æ¥æ§‹é€ ï¼‰
        pages = read_result.get("pages", [])
        if pages:
            lines = pages[0].get("lines", [])
            return "\n".join([line.get("content", "") for line in lines])

        # blockså¯¾å¿œï¼ˆã‚ˆã‚Šè©³ç´°ãªæ§‹é€ ï¼‰
        blocks = read_result.get("blocks", [])
        if blocks:
            return "\n".join([block.get("content", "") for block in blocks])

        st.warning("âš ï¸ OCRçµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return ""

    except Exception as e:
        st.error(f"âŒ OCRã‚¨ãƒ©ãƒ¼: {e}")
        return ""


# GPTã«ã‚ˆã‚‹è¦ç´„ç”Ÿæˆ
def summarize_text(text: str) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä»¥ä¸‹ã®OCRãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã‚„ã™ãæ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": text}
            ],
            temperature=0.5,
            max_tokens=600
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"âŒ è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
        return "è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ"

# Azure Blob ã«è¿½è¨˜å½¢å¼ã§CSVä¿å­˜
def save_to_azure_blob_csv_append(ocr_text: str, summary_text: str, file_name: str,
                                   container_name="ocr-results", blob_name="ocr_result.csv") -> str:
    try:
        # æ¥ç¶š
        blob_service = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        container_client = blob_service.get_container_client(container_name)
        if not container_client.exists():
            container_client.create_container()

        blob_client = container_client.get_blob_client(blob_name)

        # è¿½è¨˜å¯¾è±¡ã®æ–°ã—ã„è¡Œã‚’ä½œæˆ
        new_row = pd.DataFrame([{
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "file_name": file_name,
            "ocr_text": ocr_text.replace("\n", " "),
            "summary_text": summary_text.replace("\n", " ")
        }])

        # æ—¢å­˜ã®CSVèª­ã¿è¾¼ã¿ï¼ˆãªã‘ã‚Œã°æ–°è¦ï¼‰
        try:
            existing_data = blob_client.download_blob().readall().decode("utf-8")
            existing_df = pd.read_csv(StringIO(existing_data))
            combined_df = pd.concat([existing_df, new_row], ignore_index=True)
        except Exception:
            combined_df = new_row

        # ä¸Šæ›¸ãã§ä¿å­˜
        output = StringIO()
        combined_df.to_csv(output, index=False)
        blob_client.upload_blob(output.getvalue(), overwrite=True)

        return "âœ… Azure Blobã«CSVã‚’è¿½è¨˜ä¿å­˜ã—ã¾ã—ãŸ"

    except Exception as e:
        return f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}"
